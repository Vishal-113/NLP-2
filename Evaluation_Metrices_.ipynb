{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGWr9U17XPE/AVBAzp6AL8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishal-113/NLP-2/blob/main/Evaluation_Metrices_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect — let’s carefully compute step by step before writing the Python code.\n",
        "\n",
        "We have a **3-class confusion matrix**:\n",
        "\n",
        "| System \\ Gold      | Cat | Dog | Rabbit | **Row sum (Predicted)** |\n",
        "| ------------------ | --- | --- | ------ | ----------------------- |\n",
        "| **Cat**            | 5   | 10  | 5      | 20                      |\n",
        "| **Dog**            | 15  | 20  | 10     | 45                      |\n",
        "| **Rabbit**         | 0   | 15  | 10     | 25                      |\n",
        "| **Col sum (Gold)** | 20  | 45  | 25     | 90                      |\n",
        "\n",
        "\n",
        "## **1. Per-Class Metrics**\n",
        "\n",
        "**Definitions:**\n",
        "\n",
        "* Precision(c) = TP / (TP + FP).\n",
        "* Recall(c) = TP / (TP + FN).\n",
        "\n",
        "\n",
        "### **Cat**\n",
        "\n",
        "* TP = 5.\n",
        "* Predicted Cat = 20 → FP = 20 − 5 = 15.\n",
        "* Actual Cat = 20 → FN = 20 − 5 = 15.\n",
        "* Precision = 5/20 = **0.25**.\n",
        "* Recall = 5/20 = **0.25**.\n",
        "\n",
        "\n",
        "### **Dog**\n",
        "\n",
        "* TP = 20.\n",
        "* Predicted Dog = 45 → FP = 45 − 20 = 25.\n",
        "* Actual Dog = 45 → FN = 45 − 20 = 25.\n",
        "* Precision = 20/45 ≈ **0.4444**.\n",
        "* Recall = 20/45 ≈ **0.4444**.\n",
        "\n",
        "\n",
        "### **Rabbit**\n",
        "\n",
        "* TP = 10.\n",
        "* Predicted Rabbit = 25 → FP = 25 − 10 = 15.\n",
        "* Actual Rabbit = 25 → FN = 25 − 10 = 15.\n",
        "* Precision = 10/25 = **0.4**.\n",
        "* Recall = 10/25 = **0.4**.\n",
        "\n",
        "\n",
        " ## **2 .**Per-Class Results**\n",
        "\n",
        "* Cat: Precision = 0.25, Recall = 0.25\n",
        "* Dog: Precision ≈ 0.444, Recall ≈ 0.444\n",
        "* Rabbit: Precision = 0.40, Recall = 0.40\n",
        "\n",
        "\n",
        "## **3. Macro vs. Micro Averaging**\n",
        "\n",
        "### **Macro-Averaged Precision/Recall**\n",
        "\n",
        "* Precision\\_macro = (0.25 + 0.444 + 0.40) / 3 = 1.094 / 3 ≈ **0.3647**.\n",
        "* Recall\\_macro = same (since per-class precision = recall in this matrix) ≈ **0.3647**.\n",
        "\n",
        "\n",
        "### **Micro-Averaged Precision/Recall**\n",
        "\n",
        "* Micro = aggregate TP / aggregate predicted (precision), aggregate TP / aggregate actual (recall).\n",
        "* Total TP = 5 + 20 + 10 = 35.\n",
        "* Total predicted = 90, total actual = 90.\n",
        "* Precision\\_micro = Recall\\_micro = 35/90 ≈ **0.3889**.\n",
        "\n",
        "\n",
        "### **Interpretation**\n",
        "\n",
        "* **Macro averaging**: treats each class equally, regardless of size (good when class balance matters).\n",
        "* **Micro averaging**: aggregates across all classes, so larger classes (Dog here) influence more (good when overall accuracy matters).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fyrjp8c7Ry8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Confusion matrix\n",
        "confusion = np.array([\n",
        "    [5, 10, 5],   # Predicted Cat\n",
        "    [15, 20, 10], # Predicted Dog\n",
        "    [0, 15, 10]   # Predicted Rabbit\n",
        "])\n",
        "\n",
        "classes = [\"Cat\", \"Dog\", \"Rabbit\"]\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Per-class precision and recall\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for i in range(num_classes):\n",
        "    TP = confusion[i, i]\n",
        "    FP = confusion[i, :].sum() - TP\n",
        "    FN = confusion[:, i].sum() - TP\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    print(f\"{classes[i]} -> Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
        "\n",
        "# Macro averages\n",
        "macro_precision = np.mean(precisions)\n",
        "macro_recall = np.mean(recalls)\n",
        "\n",
        "# Micro averages\n",
        "TP_total = np.trace(confusion)\n",
        "total_pred = confusion.sum()\n",
        "micro_precision = TP_total / total_pred\n",
        "micro_recall = TP_total / total_pred  # same for precision and recall in multiclass\n",
        "\n",
        "print(\"\\nMacro-Averaged Precision:\", round(macro_precision, 4))\n",
        "print(\"Macro-Averaged Recall:\", round(macro_recall, 4))\n",
        "print(\"Micro-Averaged Precision:\", round(micro_precision, 4))\n",
        "print(\"Micro-Averaged Recall:\", round(micro_recall, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev8MMj8FSQ2B",
        "outputId": "c1144d08-c913-42da-dc95-98fe02ae40c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat -> Precision: 0.2500, Recall: 0.2500\n",
            "Dog -> Precision: 0.4444, Recall: 0.4444\n",
            "Rabbit -> Precision: 0.4000, Recall: 0.4000\n",
            "\n",
            "Macro-Averaged Precision: 0.3648\n",
            "Macro-Averaged Recall: 0.3648\n",
            "Micro-Averaged Precision: 0.3889\n",
            "Micro-Averaged Recall: 0.3889\n"
          ]
        }
      ]
    }
  ]
}